# app/services.py
"""
ä¸šåŠ¡é€»è¾‘å±‚ï¼šè´Ÿè´£åè°ƒæ•°æ®åº“ã€ç½‘ç»œå’Œæ–‡ä»¶ç³»ç»Ÿ
"""
import logging
from pathlib import Path
from typing import List, Optional, Union
from . import config
from .scanner_core import scan_single_file
from .utils import perform_random_sleep
from .logger import get_logger

logger = get_logger(__name__)

class ScanService:
    """
    æ‰«ææœåŠ¡ï¼šå°è£…æ‰€æœ‰æ‰«æç›¸å…³çš„ä¸šåŠ¡é€»è¾‘
    """
    def __init__(self, db, searcher, task_manager, result_handler, validator):
        """
        åˆå§‹åŒ–æœåŠ¡ç»„ä»¶ (ä¾èµ–æ³¨å…¥æ¨¡å¼)
        """
        self.db = db
        self.searcher = searcher
        self.task_manager = task_manager
        self.handler = result_handler
        self.validator = validator
        
        logger.debug("âœ… ScanService æœåŠ¡å±‚åŠ è½½å®Œæˆ")

    def get_pending_files(self, target_dir_str: str) -> List[Path]:
        target_dir = Path(target_dir_str)
        if not target_dir.exists():
            logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {target_dir}")
            return []
            
        all_files = [f.name for f in target_dir.iterdir() 
                     if f.suffix.lower() in ('.zip', '.rar', '.cbz')]
        
        new_names, skipped_count = self.task_manager.get_pending_tasks(
            all_files=all_files,
            target_dir=str(target_dir),
            is_debug=config.IS_DEBUG_MODE,
            debug_count=config.SCAN_LIMIT
        )
        
        pending = [target_dir / name for name in new_names]
        logger.info(f"ğŸ“‚ ç›®å½•æ€»æ•°: {len(all_files)} | å·²å…¥åº“(è·³è¿‡): {skipped_count} | å¾…å¤„ç†: {len(pending)}")
        return pending

    def scan_new_files(self, target_dir_str: str):
        """[ä¸šåŠ¡å…¥å£] æ‰«ææ–°æ–‡ä»¶"""
        files = self.get_pending_files(target_dir_str)
        self.process_batch(files, scan_mode=config.DEFAULT_MODE)

    def retry_failures(self, scan_mode='second'):
        """[ä¸šåŠ¡å…¥å£] é‡è¯•å¤±è´¥ä»»åŠ¡"""
        retry_paths = self.task_manager.get_retry_tasks()
        if not retry_paths:
            logger.info("âœ… æ²¡æœ‰éœ€è¦é‡è¯•çš„ä»»åŠ¡")
            return
        files = [Path(p) for p in retry_paths if Path(p).exists()]
        logger.info(f"ğŸ”„ æ‰¾åˆ° {len(files)} ä¸ªå¾…é‡è¯•æ–‡ä»¶ (æ¨¡å¼: {scan_mode})")
        self.process_batch(files, scan_mode=scan_mode)

    def process_duplicates(self, scan_mode='second'):
        """[ä¸šåŠ¡å…¥å£] æ‰«æé‡å¤ URL çš„æ–‡ä»¶"""
        count = self.db.find_and_store_url_duplicates()
        if count == 0:
            logger.info("âœ… æœªå‘ç°é‡å¤ URL")
            return
        logger.info(f"â™»ï¸ å‘ç° {count} ç»„é‡å¤ URLï¼Œè¯·ä½¿ç”¨ check_duplicates.py å·¥å…·æŸ¥çœ‹è¯¦æƒ…")

    def process_batch(self, files: List[Path], scan_mode: str = "cover"):
        if not files:
            logger.info("âœ… ä»»åŠ¡åˆ—è¡¨ä¸ºç©º")
            return
        
        total = len(files)
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡æ‰«æ {total} ä¸ªæ–‡ä»¶ (æ¨¡å¼: {scan_mode})")

        for idx, file_path in enumerate(files, 1):
            file_str = str(file_path)
            logger.info(f"[{idx}/{total}] å¤„ç†: {file_path.name}")
            self._process_single_file_protected(file_str, scan_mode)

    def _process_single_file_protected(self, file_path: str, scan_mode: str):
        """
        [æ ¸å¿ƒ] å¤„ç†å•ä¸ªæ–‡ä»¶
        """
        perform_random_sleep()

        # 1. æ‰§è¡Œæ‰«æ
        # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨ä¸‹å»åï¼ŒResultHandler å·²ç»åœ¨å†…éƒ¨å®Œæˆäº†ï¼š
        #    a. è·å– URL
        #    b. Validator éªŒè¯ (è·å–å…ƒæ•°æ®ã€è®¡ç®—ç›¸ä¼¼åº¦)
        #    c. å†™å…¥æ•°æ®åº“ (SUCCESS / MISMATCH / FAIL)
        res = scan_single_file(
            file_path=file_path,
            searcher=self.searcher,
            handler=self.handler,
            scan_mode=scan_mode
        )

        # 2. [ä¿®å¤] ç§»é™¤æ‰€æœ‰å†—ä½™é€»è¾‘
        # Service å±‚ä¸å†é‡å¤éªŒè¯ï¼Œåªè´Ÿè´£æ‰“å°ç®€å•çš„æµç¨‹æ—¥å¿—
        if res['success']:
             # æˆåŠŸæ—¥å¿—å·²ç»åœ¨ ResultHandler é‡Œæ‰“å°äº†ï¼Œè¿™é‡Œå¯ä»¥ä¿æŒæ²‰é»˜æˆ–ç®€å•è®°å½•
             pass
        else:
             # åªæœ‰å‡ºé”™æ—¶æ‰åœ¨è¿™é‡Œè¡¥ä¸€å¥æ—¥å¿—ï¼Œæ–¹ä¾¿å®šä½
             status = res.get('status', 'ERROR')
             msg = res.get('message', '')
             if status != 'NO_MATCH': # NO_MATCH å·²ç»åœ¨ Handler é‡Œ log è¿‡äº†
                 logger.debug(f"   -> æµç¨‹ç»“æŸ: {status} ({msg})")

    def scan_single(self, file_path: Union[str, Path], scan_mode: Optional[str] = None) -> dict:
        scan_mode = scan_mode or config.DEFAULT_MODE
        path_str = str(file_path)
        self._process_single_file_protected(path_str, scan_mode)
        
        # è¿”å›ç»“æœç”¨äº CLI æ˜¾ç¤º
        record = self.db.get_record_by_path(path_str)
        if record:
            return {
                'success': record['status'] == 'SUCCESS',
                'status': record['status'],
                'message': f"çŠ¶æ€: {record['status']} | Title: {record['title']}",
                'url': record['gallery_url'],
                'title': record['title']
            }
        return {'success': False, 'message': "æœªç”Ÿæˆè®°å½•"}
        
    def close(self):
        if self.db:
            self.db.close()