# app/services.py
"""
ä¸šåŠ¡é€»è¾‘å±‚ï¼šè´Ÿè´£åè°ƒæ•°æ®åº“ã€ç½‘ç»œå’Œæ–‡ä»¶ç³»ç»Ÿ
"""
import logging
from pathlib import Path
from typing import List, Optional, Union
from . import config
from .database import DatabaseManager
from .network import EHentaiHashSearcher
from .translator import TagTranslator
from .task_manager import TaskManager
from .result_handler import ResultHandler
from .scanner_core import scan_single_file, run_batch_scan
from .utils import perform_random_sleep
from .logger import get_logger

logger = get_logger(__name__)


class ScanService:
    """
    æ‰«ææœåŠ¡ï¼šå°è£…æ‰€æœ‰æ‰«æç›¸å…³çš„ä¸šåŠ¡é€»è¾‘
    """
    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡ç»„ä»¶"""
        self.db = DatabaseManager(config.DB_PATH, table_name=config.TARGET_TABLE)
        self.searcher = EHentaiHashSearcher(cookies=config.MY_COOKIES)
        self.translator = TagTranslator(str(config.TAG_DB_PATH))
        self.task_manager = TaskManager(self.db)
        self.handler = ResultHandler(self.db, self.translator)
        
        # åˆå§‹åŒ–åŠ¨ä½œ
        self.db.create_backup()
        if not self.searcher.verify_connection():
            logger.warning("âš ï¸ ç½‘ç»œè¿æ¥ä¸ç¨³å®š")

    def get_pending_files(self, target_dir: Path) -> List[Path]:
        """è·å–éœ€è¦æ‰«æçš„æ–‡ä»¶åˆ—è¡¨"""
        if not target_dir.exists():
            logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {target_dir}")
            return []
            
        # 1. è·å–ç£ç›˜æ–‡ä»¶
        all_files = [f.name for f in target_dir.iterdir() 
                     if f.suffix.lower() in ('.zip', '.rar', '.cbz')]
        
        # 2. ä½¿ç”¨ TaskManager ç­›é€‰
        new_names, skipped_count = self.task_manager.get_pending_tasks(
            all_files=all_files,
            target_dir=str(target_dir),
            is_debug=config.IS_DEBUG_MODE,
            debug_count=config.SCAN_LIMIT
        )
        
        # 3. æ„é€ å®Œæ•´è·¯å¾„
        pending = [target_dir / name for name in new_names]
        
        logger.info(f"ğŸ“‚ ç›®å½•æ€»æ•°: {len(all_files)} | å·²å…¥åº“(è·³è¿‡): {skipped_count} | å¾…å¤„ç†: {len(pending)}")
        return pending

    def process_batch(self, files: List[Path], scan_mode: str = "cover"):
        """æ‰¹é‡å¤„ç†æ ¸å¿ƒå¾ªç¯"""
        if not files:
            logger.info("âœ… æ²¡æœ‰å¾…å¤„ç†æ–‡ä»¶")
            return
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨ä»¥å…¼å®¹ç°æœ‰æ¥å£
        file_paths = [str(f) for f in files]
        
        # ä½¿ç”¨ scanner_core çš„æ‰¹é‡æ‰«æå‡½æ•°
        run_batch_scan(
            tasks=file_paths,
            description="æ‰¹é‡æ‰«æ",
            searcher=self.searcher,
            handler=self.handler,
            scan_mode=scan_mode
        )

    def scan_single(self, file_path: Union[str, Path], scan_mode: Optional[str] = None) -> dict:
        """æ‰«æå•ä¸ªæ–‡ä»¶"""
        scan_mode = scan_mode or config.DEFAULT_MODE
        return scan_single_file(
            file_path=str(file_path),
            searcher=self.searcher,
            handler=self.handler,
            scan_mode=scan_mode
        )

    def get_retry_files(self) -> List[str]:
        """è·å–éœ€è¦é‡è¯•çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆçŠ¶æ€ä¸º FAIL æˆ– NULL URLï¼‰"""
        return self.task_manager.get_null_url_tasks()

    def get_duplicate_files(self) -> List[str]:
        """è·å–é‡å¤ URL çš„æ–‡ä»¶åˆ—è¡¨"""
        return self.task_manager.get_duplicate_tasks()

    def close(self):
        """å…³é—­æœåŠ¡ï¼Œé‡Šæ”¾èµ„æº"""
        if self.db:
            self.db.close()

